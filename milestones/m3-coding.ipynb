{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 3: Exploratory Data Analysis and Baseline Model\n",
    "## Predicting Formula 1 Undercut Success in the Hybrid Era (2014-2020)\n",
    "\n",
    "**CS109A - Fall 2024**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Research Question](#research-question)\n",
    "2. [Data Loading and Summary](#data-loading)\n",
    "3. [Data Description and Sources](#data-description)\n",
    "4. [Data Cleaning and Validation](#data-cleaning)\n",
    "5. [Exploratory Data Analysis](#eda)\n",
    "6. [Meaningful Insights and Noteworthy Findings](#insights)\n",
    "7. [Feature Engineering](#feature-engineering)\n",
    "8. [Baseline Model](#baseline-model)\n",
    "9. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='research-question'></a>\n",
    "## 1. Finalized Research Question\n",
    "\n",
    "**Can we predict the success of an undercut pit stop strategy in Formula 1 races based on real-time race conditions?**\n",
    "\n",
    "### Background\n",
    "In Formula 1, an \"undercut\" is a strategic pit stop maneuver where a driver (B) pits before a rival driver (A) who is directly ahead. The goal is to use fresh tires to gain enough pace to overtake the rival when they eventually pit. This strategy is particularly crucial in the Hybrid Era (2014+), where aerodynamic changes made track overtaking more difficult.\n",
    "\n",
    "### Problem Statement\n",
    "Teams need to decide in real-time whether to attempt an undercut based on:\n",
    "- Current gap to the car ahead\n",
    "- Tire degradation (laps since last pit)\n",
    "- Recent pace differential\n",
    "- Circuit characteristics\n",
    "- Pit stop duration\n",
    "\n",
    "### Predictive Goal\n",
    "Build a model to predict whether an undercut attempt will successfully result in a position gain, helping teams make data-driven strategic decisions during races.\n",
    "\n",
    "### Success Metric\n",
    "Binary classification: **undercut_success** (1 = successful position gain, 0 = unsuccessful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "# Modeling libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Display settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(109)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='data-loading'></a>\n",
    "## 2. Data Loading and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this path to your data directory\n",
    "data_path = '../data/'\n",
    "\n",
    "# Load core datasets\n",
    "print(\"Loading datasets...\")\n",
    "circuits = pd.read_csv(data_path + 'circuits.csv', na_values=r'\\N')\n",
    "lap_times = pd.read_csv(data_path + 'lap_times.csv', na_values=r'\\N')\n",
    "pit_stops = pd.read_csv(data_path + 'pit_stops.csv', na_values=r'\\N')\n",
    "races = pd.read_csv(data_path + 'races.csv', na_values=r'\\N')\n",
    "results = pd.read_csv(data_path + 'results.csv', na_values=r'\\N')\n",
    "status = pd.read_csv(data_path + 'status.csv', na_values=r'\\N')\n",
    "drivers = pd.read_csv(data_path + 'drivers.csv', na_values=r'\\N')\n",
    "constructors = pd.read_csv(data_path + 'constructors.csv', na_values=r'\\N')\n",
    "\n",
    "print(\"Files loaded successfully!\\n\")\n",
    "\n",
    "# Display basic dataset information\n",
    "datasets = {\n",
    "    'circuits': circuits,\n",
    "    'lap_times': lap_times,\n",
    "    'pit_stops': pit_stops,\n",
    "    'races': races,\n",
    "    'results': results,\n",
    "    'status': status,\n",
    "    'drivers': drivers,\n",
    "    'constructors': constructors\n",
    "}\n",
    "\n",
    "print(\"Dataset Shapes:\")\n",
    "print(\"=\"*50)\n",
    "for name, df in datasets.items():\n",
    "    print(f\"{name:20s}: {df.shape[0]:8,d} rows √ó {df.shape[1]:3d} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='data-description'></a>\n",
    "## 3. Data Description and Sources\n",
    "\n",
    "### Data Source\n",
    "**Formula 1 World Championship (1950-2020)** from Kaggle  \n",
    "- Source: [Kaggle Dataset](https://www.kaggle.com/datasets/rohanrao/formula-1-world-championship-1950-2020)\n",
    "- License: CC0 - Public Domain\n",
    "- Original Source: Ergast Developer API (http://ergast.com/mrd/)\n",
    "\n",
    "### Data Collection Process\n",
    "The data was collected from official Formula 1 timing and results:\n",
    "- Race results from FIA (F√©d√©ration Internationale de l'Automobile)\n",
    "- Official lap timing data from race control\n",
    "- Pit stop information from timing systems\n",
    "- Circuit and driver metadata\n",
    "\n",
    "### Key Datasets\n",
    "\n",
    "1. **lap_times.csv**: Lap-by-lap timing (~500,000+ laps)\n",
    "2. **pit_stops.csv**: All pit stop events (~10,000+ stops)\n",
    "3. **races.csv**: Race metadata (1,100+ races)\n",
    "4. **results.csv**: Final race results (25,000+ records)\n",
    "5. **circuits.csv**: Circuit characteristics (76 circuits)\n",
    "\n",
    "### Focus: Hybrid Era (2014-2020)\n",
    "Filtering for 2014+ because:\n",
    "- Major regulation change (hybrid V6 power units)\n",
    "- Significant impact on tire management/pit strategy\n",
    "- More consistent and comparable race conditions\n",
    "- Better data quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Hybrid Era (2014+)\n",
    "MIN_YEAR = 2014\n",
    "\n",
    "modern_races = races[races['year'] >= MIN_YEAR]\n",
    "modern_race_ids = set(modern_races['raceId'])\n",
    "\n",
    "print(f\"Hybrid Era Analysis (2014-2020)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total races: {len(modern_races)}\")\n",
    "print(f\"Years covered: {modern_races['year'].min()} - {modern_races['year'].max()}\")\n",
    "print(f\"Unique circuits: {modern_races['circuitId'].nunique()}\")\n",
    "print(f\"\\nRaces per year:\")\n",
    "print(modern_races['year'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='data-cleaning'></a>\n",
    "## 4. Data Cleaning and Validation\n",
    "\n",
    "### Undercut Dataset Construction\n",
    "We build an **undercut attempts dataset** by:\n",
    "1. Identifying all pit stops in Hybrid Era races\n",
    "2. Finding situations where driver pitted with car directly ahead\n",
    "3. Tracking if rival pitted within 5-lap window\n",
    "4. Computing features: gaps, pace, tire age, positions\n",
    "5. Labeling success based on position changes after both pit stops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "WINDOW_LAPS = 5  # Rival must pit within this many laps\n",
    "\n",
    "# Filter datasets for modern era\n",
    "lt = lap_times[lap_times['raceId'].isin(modern_race_ids)].copy()\n",
    "ps = pit_stops[pit_stops['raceId'].isin(modern_race_ids)].copy()\n",
    "res = results[results['raceId'].isin(modern_race_ids)].copy()\n",
    "\n",
    "print(f\"Filtered Data (2014+):\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Lap times: {len(lt):,} records\")\n",
    "print(f\"Pit stops: {len(ps):,} records\")\n",
    "print(f\"Results: {len(res):,} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative time and recent pace\n",
    "lt = lt.sort_values(['raceId', 'driverId', 'lap'])\n",
    "lt['cum_ms'] = lt.groupby(['raceId', 'driverId'])['milliseconds'].cumsum()\n",
    "lt['prev3_mean_ms'] = lt.groupby(['raceId','driverId'])['milliseconds'] \\\n",
    "                        .transform(lambda s: s.shift(1).rolling(3, min_periods=1).mean())\n",
    "\n",
    "print(\"‚úì Calculated cumulative times and rolling pace\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify car ahead and gap\n",
    "lap_order = lt.copy()\n",
    "ahead_map = lap_order[['raceId','lap','position','driverId','cum_ms']].copy()\n",
    "ahead_map['position'] = ahead_map['position'] + 1  \n",
    "ahead_map = ahead_map.rename(columns={'driverId':'ahead_driverId','cum_ms':'ahead_cum_ms'})\n",
    "\n",
    "lap_order = lap_order.merge(ahead_map, on=['raceId','lap','position'], how='left')\n",
    "lap_order['gap_to_ahead_ms'] = lap_order['cum_ms'] - lap_order['ahead_cum_ms']\n",
    "\n",
    "print(\"‚úì Identified car ahead and calculated gaps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pit stop information\n",
    "pits_one_per_lap = (ps.sort_values(['raceId','driverId','lap','stop'])\n",
    "                      .drop_duplicates(['raceId','driverId','lap'], keep='first')\n",
    "                      [['raceId','driverId','lap','milliseconds']]\n",
    "                      .rename(columns={'milliseconds':'pit_ms'}))\n",
    "\n",
    "lap_order = lap_order.merge(pits_one_per_lap.assign(pit_flag=1),\n",
    "                             on=['raceId','driverId','lap'], how='left')\n",
    "lap_order['pit_flag'] = lap_order['pit_flag'].fillna(0).astype(int)\n",
    "\n",
    "print(\"‚úì Merged pit stop data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate stint information (tire age)\n",
    "tmp = lap_order[['raceId','driverId','lap','pit_flag']].copy()\n",
    "tmp['last_pit_lap'] = np.where(tmp['pit_flag'].eq(1), tmp['lap'], np.nan)\n",
    "tmp['last_pit_lap'] = tmp.sort_values(['raceId','driverId','lap']) \\\n",
    "                       .groupby(['raceId','driverId'])['last_pit_lap'].ffill().fillna(0)\n",
    "\n",
    "lap_order['laps_since_last_pit'] = lap_order['lap'] - tmp['last_pit_lap']\n",
    "lap_order['stint_no'] = (lap_order.sort_values(['raceId','driverId','lap'])\n",
    "                         .groupby(['raceId','driverId'])['pit_flag'].cumsum() + 1)\n",
    "\n",
    "print(\"‚úì Calculated stint information (tire age)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build undercut attempts dataset\n",
    "# Pre-pit state for trailing car (B)\n",
    "prev_state = lap_order[['raceId','driverId','lap','position','ahead_driverId',\n",
    "                        'gap_to_ahead_ms','prev3_mean_ms','laps_since_last_pit','stint_no']].copy()\n",
    "prev_state = prev_state.rename(columns={\n",
    "    'position':'b_position_prev',\n",
    "    'ahead_driverId':'a_driverId',\n",
    "    'gap_to_ahead_ms':'gap_prev_ms',\n",
    "    'prev3_mean_ms':'b_prev3_mean_ms',\n",
    "    'laps_since_last_pit':'b_laps_since_last_pit',\n",
    "    'stint_no':'b_stint_no'\n",
    "})\n",
    "prev_state['lap'] = prev_state['lap'] + 1\n",
    "\n",
    "# Pit events for driver B\n",
    "pit_events = lap_order[lap_order['pit_flag'].eq(1)][['raceId','driverId','lap','pit_ms']].copy()\n",
    "pit_events = pit_events.merge(prev_state, on=['raceId','driverId','lap'], how='left')\n",
    "pit_events = pit_events.rename(columns={'driverId':'b_driverId'})\n",
    "pit_events = pit_events[~pit_events['a_driverId'].isna()].copy()\n",
    "\n",
    "print(\"‚úì Identified potential undercut scenarios\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pre-pit metrics for car ahead (A)\n",
    "a_prev_metrics = lap_order[['raceId','driverId','lap','prev3_mean_ms',\n",
    "                            'laps_since_last_pit','stint_no']].copy()\n",
    "a_prev_metrics = a_prev_metrics.rename(columns={\n",
    "    'driverId':'a_driverId',\n",
    "    'prev3_mean_ms':'a_prev3_mean_ms',\n",
    "    'laps_since_last_pit':'a_laps_since_last_pit',\n",
    "    'stint_no':'a_stint_no'\n",
    "})\n",
    "a_prev_metrics['lap'] = a_prev_metrics['lap'] + 1\n",
    "pit_events = pit_events.merge(a_prev_metrics, on=['raceId','a_driverId','lap'], how='left')\n",
    "\n",
    "print(\"‚úì Added metrics for car ahead\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if car A pits within undercut window\n",
    "a_pits_all = ps[['raceId','driverId','lap','milliseconds']].rename(\n",
    "    columns={'driverId':'a_driverId','lap':'a_pit_lap','milliseconds':'a_pit_ms'})\n",
    "\n",
    "tmp = pit_events.merge(a_pits_all, on=['raceId','a_driverId'], how='left')\n",
    "tmp = tmp[tmp['a_pit_lap'] > tmp['lap']]\n",
    "tmp = tmp[tmp['a_pit_lap'] <= tmp['lap'] + WINDOW_LAPS]\n",
    "tmp = tmp.sort_values(['raceId','b_driverId','lap','a_pit_lap'])\n",
    "tmp = tmp.drop_duplicates(subset=['raceId','b_driverId','lap'], keep='first')\n",
    "pit_events = tmp\n",
    "\n",
    "print(f\"‚úì Filtered for undercut window ({WINDOW_LAPS} laps)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine positions after both pit stops\n",
    "pos_at_lap = lap_order[['raceId','driverId','lap','position']].copy()\n",
    "\n",
    "# A's position at end of its pit lap\n",
    "a_post = pos_at_lap.rename(columns={'driverId':'a_driverId','position':'a_position_post','lap':'pos_lap'})\n",
    "pit_events = pit_events.merge(a_post, left_on=['raceId','a_driverId','a_pit_lap'],\n",
    "                               right_on=['raceId','a_driverId','pos_lap'], how='left').drop(columns=['pos_lap'])\n",
    "\n",
    "# B's position at end of A's pit lap\n",
    "b_post = pos_at_lap.rename(columns={'driverId':'b_driverId','position':'b_position_post','lap':'pos_lap'})\n",
    "pit_events = pit_events.merge(b_post, left_on=['raceId','b_driverId','a_pit_lap'],\n",
    "                               right_on=['raceId','b_driverId','pos_lap'], how='left').drop(columns=['pos_lap'])\n",
    "\n",
    "# Label success: B ahead of A after A's pit\n",
    "pit_events['undercut_success'] = (pit_events['b_position_post'] < pit_events['a_position_post']).astype(int)\n",
    "\n",
    "print(\"‚úì Calculated position changes and labeled success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add race and grid information\n",
    "pit_events = pit_events.merge(modern_races, on='raceId', how='left')\n",
    "\n",
    "res_meta = res[['raceId','driverId','constructorId','grid']].copy()\n",
    "pit_events = pit_events.merge(\n",
    "    res_meta.rename(columns={'driverId':'b_driverId','constructorId':'b_constructorId','grid':'b_grid'}),\n",
    "    on=['raceId','b_driverId'], how='left')\n",
    "pit_events = pit_events.merge(\n",
    "    res_meta.rename(columns={'driverId':'a_driverId','constructorId':'a_constructorId','grid':'a_grid'}),\n",
    "    on=['raceId','a_driverId'], how='left')\n",
    "\n",
    "print(\"‚úì Added race metadata and constructor information\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final undercuts dataset\n",
    "undercuts = pit_events[[\n",
    "    'raceId','year','round','name','circuitId',\n",
    "    'b_driverId','a_driverId',\n",
    "    'lap','a_pit_lap',\n",
    "    'gap_prev_ms','b_prev3_mean_ms','a_prev3_mean_ms',\n",
    "    'b_laps_since_last_pit','a_laps_since_last_pit',\n",
    "    'b_stint_no','a_stint_no',\n",
    "    'pit_ms','a_pit_ms',\n",
    "    'b_position_prev','b_position_post','a_position_post',\n",
    "    'b_constructorId','a_constructorId',\n",
    "    'b_grid','a_grid',\n",
    "    'undercut_success'\n",
    "]].rename(columns={'lap':'b_pit_lap'})\n",
    "\n",
    "# Feature engineering: pace differential\n",
    "undercuts['delta_prev3_ms'] = undercuts['b_prev3_mean_ms'] - undercuts['a_prev3_mean_ms']\n",
    "\n",
    "# Convert to appropriate data types\n",
    "int_cols = ['raceId','year','round','circuitId','b_driverId','a_driverId',\n",
    "           'b_pit_lap','a_pit_lap','b_laps_since_last_pit','a_laps_since_last_pit',\n",
    "           'b_stint_no','a_stint_no','b_position_prev','b_position_post','a_position_post',\n",
    "           'b_constructorId','a_constructorId','b_grid','a_grid','undercut_success','pit_ms','a_pit_ms']\n",
    "\n",
    "undercuts[int_cols] = undercuts[int_cols].round().astype('Int64')\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA CLEANING COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Final undercut attempts dataset: {len(undercuts):,} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset summary\n",
    "print(\"\\nDataset Information:\")\n",
    "print(\"=\"*50)\n",
    "undercuts.info()\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "undercuts.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation Summary\n",
    "\n",
    "‚úì **Data Completeness**: Minimal missing values  \n",
    "‚úì **Temporal Coverage**: 2014-2020 captured  \n",
    "‚úì **Logical Consistency**: Positions and laps valid  \n",
    "‚úì **Feature Quality**: Computed correctly  \n",
    "‚úì **Target Variable**: Binary labels assigned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='eda'></a>\n",
    "## 5. Exploratory Data Analysis\n",
    "\n",
    "### 5.1 Target Variable Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "print(\"Undercut Success Distribution:\")\n",
    "print(\"=\"*50)\n",
    "success_counts = undercuts['undercut_success'].value_counts()\n",
    "success_rate = undercuts['undercut_success'].mean()\n",
    "\n",
    "print(f\"Unsuccessful (0): {success_counts[0]:,} ({100*(1-success_rate):.1f}%)\")\n",
    "print(f\"Successful (1):   {success_counts[1]:,} ({100*success_rate:.1f}%)\")\n",
    "print(f\"\\nOverall Success Rate: {100*success_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "success_counts.plot(kind='bar', ax=axes[0], color=['#e74c3c', '#2ecc71'], alpha=0.8)\n",
    "axes[0].set_title('Undercut Attempt Outcomes', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Undercut Success (0 = Failed, 1 = Success)', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_xticklabels(['Failed', 'Success'], rotation=0)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, v in enumerate(success_counts):\n",
    "    axes[0].text(i, v + 50, f'{v:,}\\n({100*v/len(undercuts):.1f}%)', \n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#e74c3c', '#2ecc71']\n",
    "axes[1].pie(success_counts, labels=['Failed', 'Success'], autopct='%1.1f%%', \n",
    "           startangle=90, colors=colors, textprops={'fontsize': 12})\n",
    "axes[1].set_title('Proportion of Undercut Success', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä KEY INSIGHT: Severe class imbalance (~94% failed)\")\n",
    "print(\"   ‚Üí Will use precision, recall, F1, AUC-ROC (not just accuracy)\")\n",
    "print(\"   ‚Üí Consider class weighting in model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Impact on Project:**\n",
    "- Severe class imbalance (~6% success)\n",
    "- Need appropriate metrics (precision, recall, F1, AUC)\n",
    "- Will use class weights in logistic regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Feature Distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert milliseconds to seconds for interpretability\n",
    "undercuts['gap_prev_sec'] = undercuts['gap_prev_ms'] / 1000\n",
    "undercuts['delta_prev3_sec'] = undercuts['delta_prev3_ms'] / 1000\n",
    "undercuts['pit_sec'] = undercuts['pit_ms'] / 1000\n",
    "undercuts['a_pit_sec'] = undercuts['a_pit_ms'] / 1000\n",
    "\n",
    "print(\"Key Feature Statistics:\")\n",
    "print(\"=\"*50)\n",
    "undercuts[['gap_prev_sec', 'delta_prev3_sec', 'b_laps_since_last_pit', \n",
    "           'a_laps_since_last_pit', 'pit_sec', 'a_pit_sec']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "features_to_plot = [\n",
    "    ('gap_prev_sec', 'Gap to Leader (sec)', 'Gap Before Undercut'),\n",
    "    ('delta_prev3_sec', 'Pace Diff (sec)', 'Recent Pace: B - A'),\n",
    "    ('b_laps_since_last_pit', 'Laps on Tire', 'Tire Age: Attacker'),\n",
    "    ('a_laps_since_last_pit', 'Laps on Tire', 'Tire Age: Leader'),\n",
    "    ('pit_sec', 'Duration (sec)', 'Pit Stop: Attacker'),\n",
    "    ('b_position_prev', 'Position', 'Race Position: Attacker')\n",
    "]\n",
    "\n",
    "for idx, (feat, xlabel, title) in enumerate(features_to_plot):\n",
    "    axes[idx].hist(undercuts[feat].dropna(), bins=30, color='steelblue', \n",
    "                   alpha=0.7, edgecolor='black')\n",
    "    axes[idx].set_title(title, fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(xlabel, fontsize=10)\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=10)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    mean_val = undercuts[feat].mean()\n",
    "    axes[idx].axvline(mean_val, color='red', linestyle='--', linewidth=2,\n",
    "                     label=f'Mean: {mean_val:.2f}')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä KEY INSIGHTS:\")\n",
    "print(\"   ‚Ä¢ Gap: Most attempts within 1-5 seconds\")\n",
    "print(\"   ‚Ä¢ Tire Age: Most attempts at 5-15 laps on tires\")\n",
    "print(\"   ‚Ä¢ Pit Stops: Mean ~23-24 sec with outliers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Impact on Project:**\n",
    "- Gap (1-5 sec) is key feature\n",
    "- Tire age (5-15 laps) critical\n",
    "- Pit stop outliers may need handling\n",
    "- Position skewed to midfield\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Correlation Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "numeric_features = ['gap_prev_ms', 'delta_prev3_ms', \n",
    "                   'b_laps_since_last_pit', 'a_laps_since_last_pit',\n",
    "                   'pit_ms', 'a_pit_ms',\n",
    "                   'b_position_prev', 'b_grid', 'a_grid',\n",
    "                   'undercut_success']\n",
    "\n",
    "corr_data = undercuts[numeric_features].dropna()\n",
    "correlation_matrix = corr_data.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelations with Target:\")\n",
    "print(\"=\"*50)\n",
    "target_corr = correlation_matrix['undercut_success'].drop('undercut_success').sort_values(ascending=False)\n",
    "print(target_corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Impact on Project:**\n",
    "- Gap to leader most important predictor\n",
    "- Low correlations suggest non-linear relationships\n",
    "- May need interaction terms or non-linear models\n",
    "- Grid position has minimal effect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Temporal Patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Success rate by year\n",
    "yearly_success = undercuts.groupby('year')['undercut_success'].agg(['mean', 'count'])\n",
    "yearly_success['success_rate'] = 100 * yearly_success['mean']\n",
    "\n",
    "print(\"Success Rate by Year:\")\n",
    "print(\"=\"*50)\n",
    "print(yearly_success[['count', 'success_rate']])\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "axes[0].plot(yearly_success.index, yearly_success['success_rate'], \n",
    "            marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "axes[0].set_title('Undercut Success Rate by Year', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Year', fontsize=12)\n",
    "axes[0].set_ylabel('Success Rate (%)', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axhline(undercuts['undercut_success'].mean() * 100, \n",
    "               color='red', linestyle='--', label='Overall Average')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].bar(yearly_success.index, yearly_success['count'], \n",
    "           color='coral', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_title('Undercut Attempts by Year', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Year', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Success varies 4-8% across years\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Circuit-Specific Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circuit success rates\n",
    "undercuts_circuits = undercuts.merge(circuits[['circuitId', 'name', 'country']], \n",
    "                                     on='circuitId', suffixes=('', '_circuit'))\n",
    "\n",
    "circuit_stats = undercuts_circuits.groupby('name_circuit').agg({\n",
    "    'undercut_success': ['mean', 'count']\n",
    "}).round(3)\n",
    "circuit_stats.columns = ['success_rate', 'attempts']\n",
    "circuit_stats = circuit_stats[circuit_stats['attempts'] >= 20]\n",
    "circuit_stats = circuit_stats.sort_values('success_rate', ascending=False)\n",
    "circuit_stats['success_pct'] = 100 * circuit_stats['success_rate']\n",
    "\n",
    "print(\"Top Circuits by Success Rate (min 20 attempts):\")\n",
    "print(\"=\"*50)\n",
    "print(circuit_stats[['attempts', 'success_pct']].head(10))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "top_circuits = circuit_stats.head(15)\n",
    "ax.barh(range(len(top_circuits)), top_circuits['success_pct'], \n",
    "       color='teal', alpha=0.7, edgecolor='black')\n",
    "ax.set_yticks(range(len(top_circuits)))\n",
    "ax.set_yticklabels(top_circuits.index, fontsize=10)\n",
    "ax.set_xlabel('Success Rate (%)', fontsize=12)\n",
    "ax.set_title('Top 15 Circuits by Undercut Success\\n(min 20 attempts)', \n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.axvline(undercuts['undercut_success'].mean() * 100, \n",
    "          color='red', linestyle='--', linewidth=2, label='Overall Avg')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Circuit matters: 2-12% success range\")\n",
    "print(\"   ‚Üí Must include circuit as categorical feature\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='insights'></a>\n",
    "## 6. Meaningful Insights and Noteworthy Findings\n",
    "\n",
    "### Key Findings Summary\n",
    "\n",
    "#### 1. **Severe Class Imbalance** üéØ\n",
    "- Only **5.9%** of undercut attempts succeed\n",
    "- **Impact**: Use precision, recall, AUC (not just accuracy)\n",
    "- **Action**: Apply class weights in models\n",
    "\n",
    "#### 2. **Gap is King** üëë\n",
    "- Gap to leader is strongest predictor\n",
    "- Most successful undercuts within **1-3 seconds**\n",
    "- **Impact**: Gap as primary feature\n",
    "\n",
    "#### 3. **Tire Age Matters** üõû\n",
    "- Optimal window: **8-15 laps** on tires\n",
    "- Fresh tire advantage crucial\n",
    "- **Impact**: Include tire age differential\n",
    "\n",
    "#### 4. **Circuit Dependencies** üèÅ\n",
    "- Success rates vary **2-12%** across circuits\n",
    "- **Impact**: Circuit as categorical feature\n",
    "\n",
    "#### 5. **Weak Linear Relationships** üìâ\n",
    "- Low correlations suggest non-linear patterns\n",
    "- **Impact**: May need complex models beyond baseline\n",
    "\n",
    "#### 6. **Temporal Stability** ‚è±Ô∏è\n",
    "- Success rates stable (4-8%) across years\n",
    "- **Impact**: Don't need time-series models\n",
    "\n",
    "### Model Strategy\n",
    "1. **Baseline**: Logistic Regression with class weights\n",
    "2. **Metrics**: Precision, recall, F1, AUC-ROC\n",
    "3. **Features**: Gap, tire age, pace, circuit, pit duration\n",
    "4. **Future**: Tree-based models for non-linear patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='feature-engineering'></a>\n",
    "## 7. Feature Engineering\n",
    "\n",
    "Based on EDA insights:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engineered features\n",
    "modeling_data = undercuts.copy()\n",
    "\n",
    "# Tire age differential\n",
    "modeling_data['tire_age_diff'] = modeling_data['b_laps_since_last_pit'] - modeling_data['a_laps_since_last_pit']\n",
    "\n",
    "# Relative pace (normalized)\n",
    "modeling_data['relative_pace'] = (modeling_data['delta_prev3_ms'] / modeling_data['a_prev3_mean_ms'])\n",
    "\n",
    "# Gap per lap\n",
    "modeling_data['gap_per_lap'] = (modeling_data['gap_prev_ms'] / (modeling_data['b_laps_since_last_pit'] + 1))\n",
    "\n",
    "# Pit stop differential\n",
    "modeling_data['pit_diff_ms'] = modeling_data['pit_ms'] - modeling_data['a_pit_ms']\n",
    "\n",
    "print(\"Feature Engineering Complete!\")\n",
    "print(\"=\"*50)\n",
    "print(\"New features:\")\n",
    "print(\"  ‚Ä¢ tire_age_diff\")\n",
    "print(\"  ‚Ä¢ relative_pace\")\n",
    "print(\"  ‚Ä¢ gap_per_lap\")\n",
    "print(\"  ‚Ä¢ pit_diff_ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='baseline-model'></a>\n",
    "## 8. Baseline Model: Logistic Regression\n",
    "\n",
    "### Rationale\n",
    "- Binary classification problem\n",
    "- Interpretable coefficients\n",
    "- Standard course baseline\n",
    "- Handles class imbalance with `class_weight`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "model_features = [\n",
    "    'gap_prev_ms', 'delta_prev3_ms',\n",
    "    'b_laps_since_last_pit', 'a_laps_since_last_pit',\n",
    "    'pit_ms', 'a_pit_ms',\n",
    "    'tire_age_diff', 'gap_per_lap',\n",
    "    'circuitId', 'year'\n",
    "]\n",
    "\n",
    "model_df = modeling_data[model_features + ['undercut_success']].dropna()\n",
    "\n",
    "print(f\"Modeling dataset: {len(model_df):,} records\")\n",
    "print(f\"Features: {len(model_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and encode\n",
    "X = model_df[model_features]\n",
    "y = model_df['undercut_success']\n",
    "\n",
    "# One-hot encode categoricals\n",
    "X_encoded = pd.get_dummies(X, columns=['circuitId', 'year'], drop_first=True)\n",
    "\n",
    "# Train-test split (70-30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.3, random_state=109, stratify=y)\n",
    "\n",
    "print(\"\\nTrain-Test Split:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training: {len(X_train):,} samples\")\n",
    "print(f\"Test: {len(X_test):,} samples\")\n",
    "print(f\"\\nSuccess rate (train): {100*y_train.mean():.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features standardized (mean=0, std=1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"Training Logistic Regression...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    random_state=109,\n",
    "    max_iter=1000,\n",
    "    solver='lbfgs'\n",
    ")\n",
    "\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"‚úì Model trained!\")\n",
    "print(\"  ‚Ä¢ Class weight: balanced\")\n",
    "print(\"  ‚Ä¢ Solver: lbfgs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_train_pred = logreg.predict(X_train_scaled)\n",
    "y_test_pred = logreg.predict(X_test_scaled)\n",
    "y_train_proba = logreg.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_proba = logreg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Predictions generated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTRAINING SET:\")\n",
    "print(\"-\"*60)\n",
    "print(f\"Accuracy:  {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_train, y_train_pred, zero_division=0):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"AUC-ROC:   {roc_auc_score(y_train, y_train_proba):.4f}\")\n",
    "\n",
    "print(\"\\nTEST SET:\")\n",
    "print(\"-\"*60)\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"AUC-ROC:   {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Failed', 'Success']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "           xticklabels=['Failed', 'Success'], yticklabels=['Failed', 'Success'])\n",
    "axes[0].set_title('Confusion Matrix - Training', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted', fontsize=11)\n",
    "axes[0].set_ylabel('Actual', fontsize=11)\n",
    "\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
    "           xticklabels=['Failed', 'Success'], yticklabels=['Failed', 'Success'])\n",
    "axes[1].set_title('Confusion Matrix - Test', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted', fontsize=11)\n",
    "axes[1].set_ylabel('Actual', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_proba)\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_proba)\n",
    "auc_train = roc_auc_score(y_train, y_train_proba)\n",
    "auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(fpr_train, tpr_train, linewidth=2, label=f'Train (AUC={auc_train:.3f})', color='blue')\n",
    "plt.plot(fpr_test, tpr_test, linewidth=2, label=f'Test (AUC={auc_test:.3f})', color='green')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve - Logistic Regression', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_names = X_encoded.columns\n",
    "coefficients = logreg.coef_[0]\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients,\n",
    "    'abs_coefficient': np.abs(coefficients)\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Most Important Features:\")\n",
    "print(\"=\"*60)\n",
    "print(feature_importance.head(15)[['feature', 'coefficient']])\n",
    "\n",
    "# Plot\n",
    "top_features = feature_importance.head(15)\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['green' if x > 0 else 'red' for x in top_features['coefficient']]\n",
    "plt.barh(range(len(top_features)), top_features['coefficient'], color=colors, alpha=0.7)\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.title('Top 15 Features (Logistic Regression)', fontsize=14, fontweight='bold')\n",
    "plt.axvline(0, color='black', linewidth=0.8)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Negative coef for gap confirms EDA: smaller gap ‚Üí success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Summary\n",
    "\n",
    "**Baseline: Logistic Regression with Balanced Class Weights**\n",
    "\n",
    "**Key Takeaways:**\n",
    "1. Model performs better than random (AUC > 0.5)\n",
    "2. Strong features: gap, tire age, circuit\n",
    "3. Room for improvement with:\n",
    "   - Non-linear models (Random Forest, XGBoost)\n",
    "   - Feature interactions\n",
    "   - Advanced sampling (SMOTE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='conclusion'></a>\n",
    "## 9. Conclusion\n",
    "\n",
    "### Summary\n",
    "\n",
    "This milestone established foundation for predicting F1 undercut success:\n",
    "\n",
    "1. **Data Preparation**: Built comprehensive dataset (2,397 records, 2014-2020)\n",
    "\n",
    "2. **EDA**: Uncovered key patterns:\n",
    "   - Severe class imbalance (6% success)\n",
    "   - Gap to leader is primary predictor\n",
    "   - Circuit characteristics matter (2-12% range)\n",
    "   - Tire age differential affects success\n",
    "\n",
    "3. **Feature Engineering**: Created meaningful features from domain knowledge\n",
    "\n",
    "4. **Baseline Model**: Logistic regression provides interpretable starting point\n",
    "\n",
    "### Next Steps\n",
    "- Implement non-linear models (Random Forest, XGBoost)\n",
    "- Add interaction terms\n",
    "- Hyperparameter tuning\n",
    "- Address imbalance with SMOTE\n",
    "- Incorporate weather/temperature\n",
    "\n",
    "### Real-World Application\n",
    "Help F1 teams:\n",
    "- Make real-time pit strategy decisions\n",
    "- Assess undercut risk vs. reward\n",
    "- Optimize tire management\n",
    "- Gain competitive advantage\n",
    "\n",
    "---\n",
    "**End of Milestone 3**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs1090a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
